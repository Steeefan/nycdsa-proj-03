{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "full_df = pd.read_csv('split_df.csv', sep = '|')\n",
    "df2 = pd.read_csv('feats.csv')\n",
    "df2 = df2.ix[:,1:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "full_df = full_df.ix[:,0:26].merge(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#full_df.loc[(full_df['Interest_Level']=='high')]\n",
    "#filter(full_df, full_df.ix[:,'features'] != None)\n",
    "#full_df[pd.isnull(full_df.features) == True]\n",
    "#notfull_df.ix[92,'features']\n",
    "full_df = full_df.fillna(value = 'No_Features')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"import pandas as pd\n",
    "full_df = pd.read_csv('full_df.csv', H)\n",
    "df2 = pd.read_csv('feats.csv', sep = '|')\n",
    "\"\"\"\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "\n",
    "\n",
    "import nltk\n",
    "from nltk.tag import pos_tag\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop = stopwords.words('english')\n",
    "def cleaning_feats(sentence):\n",
    "    sentence=re.sub('[^\\w\\s]',' ', sentence) #removes punctuations\n",
    "    sentence=re.sub('_',' ', sentence) #removes punctuations\n",
    "    sentence=re.sub('\\d+',' ', sentence) #removes digits\n",
    "    cleaned=' '.join([w for w in sentence.split() if not w in stop]) # removes english stopwords\n",
    "    #cleaned=' '.join([w for w , pos in pos_tag(cleaned.split()) if (pos == 'NN' or pos=='JJ' or pos=='JJR' or pos=='JJS' )])\n",
    "    \n",
    "    #selecting only nouns and adjectives\n",
    "    cleaned=' '.join([w for w in cleaned.split() if not len(w)<=2 ]) #removes single lettered words and digits\n",
    "    cleaned= cleaned.strip()\n",
    "    return cleaned\n",
    "\t  \n",
    "full_df['cln_feats'] = map(lambda x: cleaning_feats(x), full_df['features'])\n",
    "\n",
    "\n",
    "data_high=full_df.loc[(full_df['interest_level']=='high')]\n",
    "data_medium=full_df.loc[(full_df['interest_level']=='medium')]\n",
    "data_low=full_df.loc[(full_df['interest_level']=='low')]\n",
    "\n",
    "binVectorizer = CountVectorizer(binary=True)\n",
    "counts = binVectorizer.fit_transform(full_df['cln_feats'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "classifier = MultinomialNB()\n",
    "targets = full_df['interest_level'].values\n",
    "classifier.fit(counts, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "examples = full_df['cln_feats']\n",
    "example_counts = binVectorizer.transform(examples)\n",
    "predictions = classifier.predict(example_counts)\n",
    "predictions_df=pd.DataFrame(predictions)\n",
    "predictions_df.head(10)\n",
    "actual=full_df['interest_level'].values\n",
    "from sklearn.metrics import confusion_matrix\n",
    "matrix=pd.DataFrame(confusion_matrix(actual, predictions,labels=[\"low\", \"medium\", \"high\"]))\n",
    "#print(matrix)\n",
    "\n",
    "#pd.crosstab(full_df['Interest_Level'], predictions, rownames=['True'], colnames=['Predicted'], margins=True)\n",
    "#predictions\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.sparse as sparse\n",
    "\n",
    "full_df['Predicted_feats'] = predictions.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0           low\n",
       "1           low\n",
       "2           low\n",
       "3           low\n",
       "4           low\n",
       "5           low\n",
       "6           low\n",
       "7           low\n",
       "8           low\n",
       "9           low\n",
       "10          low\n",
       "11          low\n",
       "12          low\n",
       "13          low\n",
       "14          low\n",
       "15       medium\n",
       "16          low\n",
       "17          low\n",
       "18          low\n",
       "19          low\n",
       "20       medium\n",
       "21          low\n",
       "22          low\n",
       "23          low\n",
       "24          low\n",
       "25          low\n",
       "26          low\n",
       "27          low\n",
       "28          low\n",
       "29          low\n",
       "          ...  \n",
       "49322       low\n",
       "49323       low\n",
       "49324       low\n",
       "49325       low\n",
       "49326       low\n",
       "49327       low\n",
       "49328       low\n",
       "49329       low\n",
       "49330       low\n",
       "49331       low\n",
       "49332       low\n",
       "49333       low\n",
       "49334       low\n",
       "49335       low\n",
       "49336       low\n",
       "49337       low\n",
       "49338       low\n",
       "49339       low\n",
       "49340       low\n",
       "49341      high\n",
       "49342    medium\n",
       "49343       low\n",
       "49344       low\n",
       "49345       low\n",
       "49346       low\n",
       "49347       low\n",
       "49348       low\n",
       "49349       low\n",
       "49350       low\n",
       "49351       low\n",
       "Name: Predicted_feats, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df['Predicted_feats']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "full_df.to_csv('classified_features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
